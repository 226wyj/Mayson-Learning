# MIT 18.065 Matrix Methods by Prof. Gilbert Strang

| LEC# | TITLE                                                       | Reading      | Assignment                 |
| ---- | ----------------------------------------------------------- | ------------ | -------------------------- |
| 1    | The Column Space of A Contains All Vectors Ax ✅             | I.1 ✅        | I.1[1,4,9,18] ✅            |
| 2    | Multiplying and Factoring Matrices ✅                        | I.2 ✅        | I.2[2,6] ✅                 |
| 3    | Orthonormal Columns In Q Give Q’Q= I ✅                      | I.5 ✅        | I.5[2,4,6,7] ✅             |
| 4    | Eigenvalues and Eigenvectors ✅                              | I.6 ✅        | I.6[1,2,11,15,16,19] ✅     |
| 5    | Positive Definite and Semidefinite Matrices ✅               | I.7 ✅        | I.7[3,14,15,23,24,26,28] ✅ |
| 6    | Singular Value Decomposition (SVD) ✅                        | I.8 ✅        | I.8[6,7,8] ✅               |
| 9    | Four Ways to Solve Least Squares Problems ✅                 | II.2         |                            |
| 10   | Survey of Difficulties with Ax = b                          | Intro Ch.2   |                            |
| 11   | Minimizing ‖x‖ Subject to Ax = b                            | I.11         |                            |
| 12   | Computing Eigenvalues and Singular Values                   | II.1         |                            |
| 13   | Randomized Matrix Manipulation                              | II.4         |                            |
| 14   | Low Rank Changes in A and Its Inverse                       | III.1        |                            |
| 15   | Matrices A(t) depending on t / Derivative = dA/dt           | III.1-2      |                            |
| 16   | Derivatives of Inverse and Singular Values                  | III.1-2      |                            |
| 17   | Rapidly Decreasing Singular Values                          | III.3        |                            |
| 18   | Counting Parameters in SVD, LU, QR, Saddle Points           | III.2        |                            |
| 19   | Saddle Points Continued / Maxmin Principle                  | III.2, V.1   |                            |
| 20   | Definitions and Inequalities                                | V.1, V.3     |                            |
| 21   | Minimizing a Function Step by Step                          | VI.1, VI.4   |                            |
| 22   | Gradient Descent: Downhill to a Minimum                     | VI.4         |                            |
| 23   | Accelerating Gradient Descent (Use Momentum)                | VI.4         |                            |
| 24   | Linear Programming and TwoPerson Games                      | VI.2, VI.3   |                            |
| 25   | Stochastic Gradient Descent                                 | VI.5         |                            |
| 26   | Structure of Neural Nets for Deep Learning                  | VII.1        |                            |
| 27   | Backpropagation to Find Derivative of the Learning Function | VII.2        |                            |
| 28   | Computing in Class                                          | VII.2        |                            |
| 30   | Completing a Rank-One Matrix / Circulants!                  | IV.8, IV.2   |                            |
| 31   | Eigenvectors of Circulant Matrices: Fourier Matrix          | IV.2         |                            |
| 32   | ImageNet is a CNN / The Convolution Rule                    | IV.2         |                            |
| 33   | Neural Nets and the Learning Function                       | VII.1, IV.10 |                            |
| 34   | Distance Matrices / Procrustes Problem / First Project      | IV.9, IV.10  |                            |
| 35   | Finding Clusters in Graphs / Second Project: Handwriting    | IV.6, IV.7   |                            |

---

### MIT 18.06 Linear Algebra by Prof. Gilbert Strang
- SES#14 Orthogonality ✅
- SES#15 Projections and subspaces ✅
- SES#16 Least squares approximations 
- SES#17 Gram-Schmidt and A = QR 
- PS#5


<!-- | 7    | Eckart-Young: The Closest Rank k Matrix to A ✅              | I.9          |                            |
| 8    | Norms of Vectors and Matrices ✅                             | I.11         |                            | -->